{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, concatenate, Input\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.utils import to_categorical\n",
    "from sklearn import metrics\n",
    "import h5py\n",
    "from sklearn import utils\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.losses import categorical_crossentropy as cce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def base_cnn():\n",
    "    modelE = keras.models.Sequential()\n",
    "    modelE.add(Conv2D(32, (3, 3), input_shape=(128, 128,1)))\n",
    "    modelE.add(Activation('relu'))\n",
    "    modelE.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    modelE.add(Conv2D(32, (3, 3)))\n",
    "    modelE.add(Activation('relu'))\n",
    "    modelE.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    modelE.add(Conv2D(64, (3, 3)))\n",
    "    modelE.add(Activation('relu'))\n",
    "    modelE.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    modelE.add(Conv2D(64, (3, 3)))\n",
    "    modelE.add(Activation('relu'))\n",
    "    modelE.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    modelE.add(Conv2D(64, (3, 3)))\n",
    "    modelE.add(Activation('relu'))\n",
    "    modelE.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    modelE.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    modelE.add(Dense(64))\n",
    "    modelE.add(Activation('relu'))\n",
    "    modelE.add(Dropout(0.5))\n",
    "    modelE.add(Dense(1))\n",
    "    modelE.add(Activation('sigmoid'))\n",
    "\n",
    "    modelE.compile(loss='mean_absolute_error',\n",
    "                optimizer='Adadelta',\n",
    "                metrics=['accuracy'])\n",
    "    return modelE\n",
    "\n",
    "def train_base_cnns(train_generator,val_generator):\n",
    "    model1 = base_cnn()\n",
    "    model1.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=2500,\n",
    "            epochs=4,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=100,\n",
    "            verbose = 0)\n",
    "    model2 = base_cnn()\n",
    "    model2.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=2500,\n",
    "            epochs=4,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=100,\n",
    "            verbose = 0)\n",
    "    model3 = base_cnn()\n",
    "    model3.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=2500,\n",
    "            epochs=4,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=100,\n",
    "            verbose = 0)\n",
    "    model4 = base_cnn()\n",
    "    model4.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=2500,\n",
    "            epochs=10,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=100,\n",
    "            verbose = 0)\n",
    "    model5 = base_cnn()\n",
    "    model5.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=2500,\n",
    "            epochs=4,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=100,\n",
    "            verbose = 0)\n",
    "    model6 = base_cnn()\n",
    "    model6.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=2500,\n",
    "            epochs=4,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=100,\n",
    "            verbose = 0)\n",
    "    model7 = base_cnn()\n",
    "    model7.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=2500,\n",
    "            epochs=4,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=100,\n",
    "            verbose = 0)\n",
    "    model8 = base_cnn()\n",
    "    model8.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=2500,\n",
    "            epochs=4,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=100,\n",
    "            verbose = 0)\n",
    "    model9 = base_cnn()\n",
    "    model9.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=2500,\n",
    "            epochs=4,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=100,\n",
    "            verbose = 0)\n",
    "    model10 = base_cnn()\n",
    "    model10.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=2500,\n",
    "            epochs=4,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=100,\n",
    "            verbose = 0)\n",
    "\n",
    "    return model1,model2,model3,mode4,model5,model6,model7,model8,model9,model10\n",
    "\n",
    "def ensemble_net(model1,model2,model3,mode4,model5,model6,model7,model8,model9,model10):\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    m1 = model1(inputs)\n",
    "    m2 = model2(inputs)\n",
    "    m3 = model3(inputs)\n",
    "    m4 = model4(inputs)\n",
    "    m5 = model5(inputs)\n",
    "    m6 = model6(inputs)\n",
    "    m7 = model7(inputs)\n",
    "    m8 = model8(inputs)\n",
    "    m9 = model9(inputs)\n",
    "    m10 = model10(inputs)\n",
    "    avg = Average()([m1,m2,m3,m4,m5,m6,m7,m8,m9,m10])\n",
    "    dense = Dense(1)(avg)\n",
    "    model = Model(inputs, dense)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = base_cnn()\n",
    "model2 = base_cnn()\n",
    "model3=base_cnn()\n",
    "model4 = base_cnn()\n",
    "model5 = base_cnn()\n",
    "model6 = base_cnn()\n",
    "model7 = base_cnn()\n",
    "model8=base_cnn()\n",
    "model9 = base_cnn()\n",
    "model10 = base_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.load_weights('savio_nets/sub_models_ensemble/cnn_ensemble_10pwrongleftrightlabels_v1_model1.h5')\n",
    "model2.load_weights('savio_nets/sub_models_ensemble/cnn_ensemble_10pwrongleftrightlabels_v1_model2.h5')\n",
    "model3.load_weights('savio_nets/sub_models_ensemble/cnn_ensemble_10pwrongleftrightlabels_v1_model3.h5')\n",
    "model4.load_weights('savio_nets/sub_models_ensemble/cnn_ensemble_10pwrongleftrightlabels_v1_model4.h5')\n",
    "model5.load_weights('savio_nets/sub_models_ensemble/cnn_ensemble_10pwrongleftrightlabels_v1_model5.h5')\n",
    "model6.load_weights('savio_nets/sub_models_ensemble/cnn_ensemble_10pwrongleftrightlabels_v1_model6.h5')\n",
    "model7.load_weights('savio_nets/sub_models_ensemble/cnn_ensemble_10pwrongleftrightlabels_v1_model7.h5')\n",
    "model8.load_weights('savio_nets/sub_models_ensemble/cnn_ensemble_10pwrongleftrightlabels_v1_model8.h5')\n",
    "model9.load_weights('savio_nets/sub_models_ensemble/cnn_ensemble_10pwrongleftrightlabels_v1_model9.h5')\n",
    "model10.load_weights('savio_nets/sub_models_ensemble/cnn_ensemble_10pwrongleftrightlabels_v1_model10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_shuff = np.load('Te_X_val_shuff_20200820.npy')\n",
    "Y_val_shuff = np.load('Te_Y_val_shuff_20200820.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pred = []\n",
    "for idx in np.arange(0,X_val_shuff.shape[0]):\n",
    "    m1 = model1.predict(X_val_shuff[idx:idx+1])\n",
    "    m2 = model2.predict(X_val_shuff[idx:idx+1])\n",
    "    m3 = model3.predict(X_val_shuff[idx:idx+1])\n",
    "    m4 = model4.predict(X_val_shuff[idx:idx+1])\n",
    "    m5 = model5.predict(X_val_shuff[idx:idx+1])\n",
    "    m6 = model6.predict(X_val_shuff[idx:idx+1])\n",
    "    m7 = model7.predict(X_val_shuff[idx:idx+1])\n",
    "    m8 = model8.predict(X_val_shuff[idx:idx+1])\n",
    "    m9 = model9.predict(X_val_shuff[idx:idx+1])\n",
    "    m10 = model10.predict(X_val_shuff[idx:idx+1])\n",
    "    avg_pred.append(np.average([m1,m2,m3,m4,m5,m6,m7,m8,m9,m10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pred = np.array(avg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val_shuff[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9226804123711341"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(Y_val_shuff[:,0],avg_pred>0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fouriernet)",
   "language": "python",
   "name": "fouriernet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
